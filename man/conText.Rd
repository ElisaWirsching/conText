% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/conText.R
\name{conText}
\alias{conText}
\title{Embedding regression}
\usage{
conText(
  formula,
  data,
  pre_trained,
  transform = TRUE,
  transform_matrix,
  bootstrap = TRUE,
  num_bootstraps = 20,
  stratify = TRUE,
  permute = TRUE,
  num_permutations = 100,
  window = 6L,
  valuetype = c("glob", "regex", "fixed"),
  case_insensitive = TRUE,
  hard_cut = FALSE,
  verbose = TRUE
)
}
\arguments{
\item{formula}{a symbolic description of the model to be fitted
to use a phrase as a DV, wrap in quotations e.g. "immigrant refugees" ~ party + gender}

\item{data}{a quanteda \code{tokens} object}

\item{pre_trained}{a F x D matrix of numeric values corresponding to pretrained embeddings
F = number of features and D = embedding dimensions.
rownames(pre_trained) = set of features for which there is a pre-trained embedding}

\item{transform}{(logical) if TRUE (default) apply the \verb{a la carte} transformation,
if FALSE ouput untransformed averaged embedding}

\item{transform_matrix}{a D x D matrix of numeric values corresponding
to the `a la carte`` transformation matrix}

\item{bootstrap}{(logical) if TRUE, bootstrap regression - required to get standard errors for normed coefficients}

\item{num_bootstraps}{(numeric) number of bootstraps to use}

\item{stratify}{(logical) if TRUE, stratify by covariates when bootstrapping}

\item{permute}{(logical) if TRUE, compute empirical p-values using permutation test}

\item{num_permutations}{(numeric) number of permutations to use}

\item{window}{the number of context words to be displayed around the keyword}

\item{valuetype}{the type of pattern matching: \code{"glob"} for "glob"-style
wildcard expressions; \code{"regex"} for regular expressions; or \code{"fixed"} for
exact matching. See \link[quanteda]{valuetype} for details.}

\item{case_insensitive}{logical; if \code{TRUE}, ignore case when matching a
\code{pattern} or \link[quanteda]{dictionary} values}

\item{hard_cut}{logical - if TRUE then the text must have window x 2 tokens,
if FALSE it can have window x 2 or fewer (e.g. if a doc begins with a target word,
then text will have window tokens rather than window x 2)}

\item{verbose}{logical - report the documents/features that had
no overlap with the provided pre-trained embeddings}
}
\value{
a \code{conText-class} object
}
\description{
Estimate an embedding regression model
}
\examples{

library(quanteda)

cr_toks <- tokens(cr_sample_corpus)

## given the target word "immigration"
model1 <- conText(formula = immigration ~ party + gender,
                  data = cr_toks,
                  pre_trained = glove_subset,
                  transform = TRUE, transform_matrix = khodakA,
                  bootstrap = TRUE, num_bootstraps = 10,
                  stratify = TRUE,
                  permute = TRUE, num_permutations = 100,
                  window = 6, case_insensitive = TRUE,
                  hard_cut = FALSE,
                  verbose = FALSE)

# notice, non-binary covariates are automatically "dummified"
rownames(model1)

# the beta coefficient 'partyR' in this case corresponds to the alc embedding
# of "immigration" for Republican party speeches

# (normed) coefficient table
model1@normed_cofficients

}
\keyword{conText}
